---
title: "Week 10 Lab solution"
author: "key"
date: "Submission date"
output:
  html_document: default
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Exercises

# Ex 1 (tomatos)

Revisit the tomato data from Lab 8.  

a. Find a simple linear regression line that can predict the tomato height at measurement 2 (height2) using the pH measurement.  Report the slope and intercept of the regression line.

**Answer.**
The intercept of the line is 11.0568 and the slope is 0.6095. 
```{r}
tomato <- read.csv("Data/tomato.csv",header=T)
lm_tomato <- lm(height2~ph,data=tomato)
summary(lm_tomato)
```

b. Use your answer from part (a) to predict the height at measurement 2 for a tomato plant whose soil pH is 5.1.

**Answer.**
The regression line predicts that the height 2 of a plants whose soil pH is 5.1 will be 14.165 cm.  The code I used is below.
```{r}
coefficients <- summary(lm_tomato)$coefficients
intercept <- coefficients[1,1]
slope <- coefficients[2,1]

new_x <- 5.1
prediction <- intercept + new_x*slope
prediction
```

c. Find 95\% confidence intervals for the slope of the regression line.

**Answer.**
I am 95\% confident that the true intercept is between 9.5834 and 12.53. I am 95\% confident that the true slope is between 0.296 and 0.923. See the code below for two approaches to finding the CIs.

```{r}
# short way
confint(lm_tomato, level=0.95) 
```

```{r}
# long way
beta0.hat <- summary(lm_tomato)$coefficients[1,1]
beta1.hat <-summary(lm_tomato)$coefficients[2,1]
se.beta0 <- summary(lm_tomato)$coefficients[1,2]
se.beta1 <- summary(lm_tomato)$coefficients[2,2]
tstar <- qt(0.975, df=nrow(tomato)-2)

ci.beta0 <- c(beta0.hat - tstar*se.beta0, beta0.hat + tstar*se.beta0)
ci.beta0

ci.beta1 <- c(beta1.hat - tstar*se.beta1, beta1.hat + tstar*se.beta1)
ci.beta1
```

## Ex 2: (Expenditures)

 The data set `2015\_revenue\_expenditures.csv`  contains records of government revenue and expenditures for 150 of the largest cities in the U.S in 2015.  Among the variables measured are `Intergovt revenue`, which records the total revenue in the cities coming from state and federal government, and expenditures in various spending categories. 

a. Find the simple linear regression equation to predict expenditures in education services (`Education Services Expend`.) from  `Intergovt revenue`.  Give the estimated regression equation.  

**Answer.**
The estimated regression equation is

Education services expenditures = 807.36295 + 0.48871*Intergovt revenue

R code:
```{r}
expenditures <- read.csv("Data/2015_revenue_expenditures.csv")
lm_expen <- lm(Education.Services.Expend.~Intergovt.Revenue,data=expenditures)
summary(lm_expen)
```

b. Perform a test of the hypotheses 

$$H_0: \beta_1 = 0; \quad H_A: \beta_1 > 0.$$

Use $\alpha=0.01$. Report the test statistic, p-value, decision, and conclusion in the context of the problem. 

**Answer.**

The test statistic is $t_0 =13.14$, which can be calculated using the formula or just read off of the table printed above. The p-value cannot be read from the table because the alternative is one-sided. I'll use the `pt` function to find the upper-tail probability of the test statistic.

The p-value is approximately zero (less than $1\times 10^{-16}$), so the null hypothesis is rejected. There is strong evidence in the data that the slope is greater than zero.

```{r}
t0 <- summary(lm_expen)$coefficients[2,1]/summary(lm_expen)$coefficients[2,2]
t0
pt(t0, df=nrow(expenditures)-2, lower.tail=FALSE)
```

c. Create a plot of the x variable vs residuals.  Also create a Normal quantile plot of the residuals.  Write a sentence explaining whether the modeling assumptions of normality and equal variances appear to be reasonable for these data.

**Answer.**
The code below produces the two plots. There seems to be a slight increase in residual variability as the intergoverment revenue increases, indicating a mild violation of the equality of variances assumption. The plot does not suggest a violation of the linearity assumption.

The normal quantile plot shows that the lower and upper tails of the distribution deviate from normality somewhat. In short, the data do not conform completely to our modeling assumptions. The violations are not so extreme, however, that we need to abandon the analysis.

```{r}
par(mfrow=c(1,2))
plot(expenditures$Intergovt.Revenue, residuals(lm_expen),
     xlab='intergovt revenue', ylab='residuals')
qqnorm(residuals(lm_expen))
qqline(residuals(lm_expen),col='red')
```


d. Find the observation in the data set for VA: Chesapeake.  What is the observed value of $y_i$, the response variable, for this observation?  

**Answer.**

The code below uses the function `substr` to find the observations from Virginia, which show that observation 136 is from Chesapeake. If you are interested, see the documentation for this function. Otherwise you can just view the data set to find which observation is from Chesapeake. 

This observation had an observed response of 1951.

```{r}
virginia <- which(substr(expenditures$Label,1,2)=='VA')
expenditures[virginia,]$Education.Services.Expend.

# save observed value
observed.chesapeake <- expenditures$Education.Services.Expend.[136]
observed.chesapeake
```

e.  What value does the estimated regression line from part (a) predict for this observation? 

**Answer.**
The model predicts education expenditures of 1691.439.

```{r}
pred.chesapeake <- fitted(lm_expen)[136]
pred.chesapeake
```

f. Calculate its residual by subtracting the predicted value from the observed value. ($\widehat{\epsilon}_i = y_i - \widehat{y}_i$.)  You can compare this to the value automatically calculated by R using the `residuals` function to check your answer.

**Answer.**
The residual is observed- predicted, which equals 259.5612.

```{r}
observed.chesapeake - pred.chesapeake

# verify that it matches what is given by residuals function
residuals(lm_expen)[136]
```

## Ex 3: (body fat)

The data set `BodyFat.csv` on Canvas contains body fat percentage and several other measurements for a sample of 253 men.  Direct measurement body fat percentage can be a cumbersome process, so it might be useful to find a different measurement that is an accurate predictor of body fat.   

a. Find a regression line that predicts `BODYFAT` from `WEIGHT`.  Write the estimated regression equation and the $R^2$ for this model.

**Answer.**
The estimated regression equation is

Bodyfat = -9.99515 + 0.16171*Weight

and the R-squared value is 0.376. The R code is below.

```{r}
bodyfat <- read.csv("Data/BodyFat.csv")
lm_bodyfat <- lm(BODYFAT~WEIGHT,data=bodyfat)
summary(lm_bodyfat)
```

b. Now find a regression line that predicts `BODYFAT` from `ABDOMEN` (the abdomen circumference).  Write the estimated regression equation and the $R^2$ for this model.

**Answer.**
The estimated regression equation is

Bodyfat=-35.19661 + 0.58489Abdomen

and the R-squared is 0.6621.

```{r}
lm_bodyfat2 <- lm(BODYFAT~ABDOMEN,data=bodyfat)
summary(lm_bodyfat2)
```

c. Based on the $R^2$ values, is weight or abdomen circumference a stronger predictor of of body fat?  (Which variable accounts for a greater proportion of the variability in body fat measurements?)

**Answer.**
The R-squared value is higher for the model using abdomen circumference than that of the model using weight as a predictor.  The regression line using abdomen explains a higher percentage of the variability in body fat, and thus, abdomen is a stronger predictor.



# Ex 4 (more diabetes)

Revisit the diabetes data from Lab 8.  


a. Provide a descriptive plot and summary statistic that describes the relationship between glucose (glu) and diastolic blood pressure (bp).  Does there appear to be a strong association between the two variables?

**Answer.**
There is not an apparent pattern in the scatterplot.  To me, it does not indicate much association between glucose and blood pressure.  The sample correlation is 0.3216, indicating a weak positive association between the variables.
```{r}
diabetes <- read.csv("Data/diabetes_sm.csv")
plot(diabetes$glu, diabetes$bp, xlab='glucose',ylab='blood pressure (diastolic)')
cor(diabetes$glu, diabetes$bp)
```

b. Fit a simple linear regression line to predict glucose (glu) using blood pressure (bp). Report the slope and intercept of the estimate regression line. Give a one-sentence interpretation of the value of the slope.

**Answer.**
The estimated intercept is 69.2087 and the estimated slope is 0.7381.  Glucose is estimated to increase by 0.7381 units for each unit increase in the diastolic blood pressure.
```{r}
lm_diabetes <- lm(glu~bp,data=diabetes)
summary(lm_diabetes)
```

c. Make 90% confidence intervals for the intercept and slope of the regression line. 

**Answer.**
The 90\% CI for the intercept is (28.747, 109.671). The 90\% CI for the slope is (0.174,  1.302).

```{r}
confint(lm_diabetes, level=0.90)
```

d. Make a plot of the fitted values vs. the residuals. Do the assumptions of equal variances and linearity appear to be reasonable?

**Answer.**
The plot below shows residuals that look like a random cloud of points. This indicates the equal variances and linearity are reasonable assumptions.

```{r}
plot(fitted(lm_diabetes), residuals(lm_diabetes),
     xlab='fitted values', ylab='residuals')
```


e. Make a normal quantile plot of the residuals. Does the assumption of normality appear to be reasonable?

**Answer.**
There is some non-normality in the residuals, which can be detected by noticing the curvature in the quantile plot.

```{r}
qqnorm(residuals(lm_diabetes))
qqline(residuals(lm_diabetes),col='navy')
```